# Docker Compose for GPU-enabled services
# Requires NVIDIA Docker runtime and nvidia-docker-compose
#
# Usage:
#   docker compose -f docker-compose.gpu.yml up
#
# Prerequisites:
#   - NVIDIA GPU with CUDA support
#   - NVIDIA Docker runtime installed
#   - nvidia-container-toolkit installed
#
# Verify GPU access: docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

services:
  # Infrastructure services (same as regular docker-compose.yml)
  nats:
    image: nats:latest
    ports:
      - "4222:4222"
      - "8222:8222"
    command: ["-js", "-m", "8222"]
    volumes:
      - nats-data:/data
    healthcheck:
      test: ["CMD", "/nats-server", "--help"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: lameness_db
      POSTGRES_USER: lameness_user
      POSTGRES_PASSWORD: lameness_pass
    ports:
      - "5434:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U lameness_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6335:6333"
      - "6336:6334"
    volumes:
      - qdrant-data:/qdrant/storage
    healthcheck:
      test: ["CMD-SHELL", "timeout 2 bash -c '</dev/tcp/localhost/6333' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # GPU-enabled ML Pipeline Services
  yolo-pipeline:
    build:
      context: .
      dockerfile: services/yolo-pipeline/Dockerfile.gpu
    image: yolo-pipeline-gpu:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    depends_on:
      - nats
    restart: unless-stopped

  sam3-pipeline:
    build:
      context: .
      dockerfile: services/sam3-pipeline/Dockerfile.gpu
    image: sam3-pipeline-gpu:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    depends_on:
      - nats
    restart: unless-stopped

  dinov3-pipeline:
    build:
      context: .
      dockerfile: services/dinov3-pipeline/Dockerfile.gpu
    image: dinov3-pipeline-gpu:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - QDRANT_URL=http://qdrant:6333
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    depends_on:
      - nats
      - qdrant
    restart: unless-stopped

  tleap-pipeline:
    build:
      context: .
      dockerfile: services/tleap-pipeline/Dockerfile.gpu
    image: tleap-pipeline-gpu:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - PYTHONUNBUFFERED=1
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    depends_on:
      - nats
    restart: unless-stopped

  tcn-pipeline:
    build:
      context: .
      dockerfile: services/tcn-pipeline/Dockerfile.gpu
    image: tcn-pipeline-gpu:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    depends_on:
      - nats
      - tleap-pipeline
    restart: unless-stopped

  transformer-pipeline:
    build:
      context: .
      dockerfile: services/transformer-pipeline/Dockerfile.gpu
    image: transformer-pipeline-gpu:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    depends_on:
      - nats
      - tleap-pipeline
    restart: unless-stopped

  gnn-pipeline:
    build:
      context: .
      dockerfile: services/gnn-pipeline/Dockerfile.gpu
    image: gnn-pipeline-gpu:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    depends_on:
      - nats
      - dinov3-pipeline
    restart: unless-stopped

  graph-transformer-pipeline:
    build:
      context: .
      dockerfile: services/graph-transformer-pipeline/Dockerfile.gpu
    image: graph-transformer-pipeline-gpu:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 8G
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
    depends_on:
      - nats
      - dinov3-pipeline
    restart: unless-stopped

  # Non-GPU services can use regular images
  video-ingestion:
    build:
      context: .
      dockerfile: services/video-ingestion/Dockerfile
    volumes:
      - ./data/videos:/app/data/videos
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - POSTGRES_URL=postgresql://lameness_user:lameness_pass@postgres:5432/lameness_db
      - POSTGRES_PORT=5433
    depends_on:
      nats:
        condition: service_healthy
      postgres:
        condition: service_healthy
    ports:
      - "8001:8000"

  video-preprocessing:
    build:
      context: .
      dockerfile: services/video-preprocessing/Dockerfile
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
    depends_on:
      - nats
      - video-ingestion

  clip-curation:
    build:
      context: .
      dockerfile: services/clip-curation/Dockerfile
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
    depends_on:
      - nats
      - video-ingestion

  tracking-service:
    build:
      context: .
      dockerfile: services/tracking-service/Dockerfile
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - POSTGRES_URL=postgresql://lameness_user:lameness_pass@postgres:5432/lameness_db
      - QDRANT_URL=http://qdrant:6333
    depends_on:
      - nats
      - postgres
      - qdrant
      - yolo-pipeline
      - dinov3-pipeline

  ml-pipeline:
    build:
      context: .
      dockerfile: services/ml-pipeline/Dockerfile
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - POSTGRES_URL=postgresql://lameness_user:lameness_pass@postgres:5432/lameness_db
      - POSTGRES_PORT=5433
    depends_on:
      - nats
      - postgres
      - yolo-pipeline
      - sam3-pipeline
      - dinov3-pipeline
      - tleap-pipeline

  fusion-service:
    build:
      context: .
      dockerfile: services/fusion-service/Dockerfile
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
    depends_on:
      - nats
      - ml-pipeline

  admin-backend:
    build:
      context: .
      dockerfile: services/admin-interface/backend/Dockerfile
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 512M
    volumes:
      - ./data:/app/data
      - ./shared:/app/shared
    environment:
      - NATS_URL=nats://nats:4222
      - POSTGRES_URL=postgresql://lameness_user:lameness_pass@postgres:5432/lameness_db
      - POSTGRES_PORT=5433
      - QDRANT_URL=http://qdrant:6333
      - STORAGE_BACKEND=local
    depends_on:
      - nats
      - postgres
      - qdrant
      - fusion-service
    ports:
      - "8000:8000"

  admin-frontend:
    build:
      context: .
      dockerfile: services/admin-interface/frontend/Dockerfile
    volumes:
      - ./services/admin-interface/frontend:/app
      - /app/node_modules
    environment:
      - VITE_API_URL=http://localhost:8000
    depends_on:
      - admin-backend
    ports:
      - "3000:3000"

volumes:
  nats-data:
  postgres-data:
  qdrant-data:
